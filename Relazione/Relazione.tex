\input{preamble.tex}

\title{Ingegneria dei Sistemi Software M}
\date{A.A. 2017--2018}
\author{Marco Boschi, Marco Rossini}

\begin{document}

\maketitletoc

\section{Analisi dei requisiti}
Il robot DDR è un dispositivo in grado di muoversi in un ambiente attraverso comandi remoti per avanzare, indietreggiare o girare di \ang{90} a destra o sinistra oltre al comando di stop. L'ambiente in cui dovrà muoversi è una stanza quadrata che può essere sia fisica che virtuale. La stanza è dotata di due sonar: uno, detto \texttt{sonar1}, è posto in alto a sinistra e rivolto verso il basso, l'altro, detto \texttt{sonar2}, è posto in basso a destra rivolto verso sinistra.

Il robot dovrà muoversi da una posizione iniziale intercettata da \texttt{sonar1}, detta \texttt{start-point}, e muoversi lungo la stanza fino alla posizione finale, detta \texttt{end-point}, intercettata da \texttt{sonar2}, pulendo la maggior superficie possibile di pavimento. I punti iniziale e finale non sono individuati solo dai sonar, ma anche dai punti a loro vicini.

Per \textit{sonar} si intende un dispositivo, reale o virtuale, che sfrutta una qualche tecnologia per individuare quando il robot passa davanti a questo.

Il robot è controllato attraverso un'interfaccia grafica, detta \texttt{console}, accessibile ad un utente umano autorizzato dall'inserimento di credenziali riconosciute dal sistema. L'attività di pulizia è innescata dall'invio del comando \texttt{START} da parte dell'utente autorizzato che controlla il robot. Ciò avviene mediante un qualunque dispositivo in grado di connettersi alla console, sarà quest'ultima a connettersi al robot. Se il robot non è rilevato (entro una certa distanza) dal \texttt{sonar1} all'invio del comando \texttt{START}, il robot non parte con l'attività di pulizia automatica. 

L'utente può comandare solo \texttt{START} o \texttt{STOP}, e non deve disporre di comandi manuali per pilotare il robot.

Il robot lavora solo se la temperatura dell'ambiente non è superiore ad una soglia prefissata e se l'ora corrente è all'interno di un intervallo prefissato. Il robot è dotato di un sensore di temperatura e di un orologio per verificare queste condizioni.

Durante l'attività di pulizia, il robot deve far lampeggiare una lampada a led Hue, ovvero una lampadina, connessa alla rete, che può essere controllata in luminosità, accensione, spegnimento e colore attraverso API RESTful.

Durante l'attività di pulizia, il robot deve inoltre aver cura di evitare ostacoli, fissi e mobili, presenti nella stanza. Si suppone che non vi siano ostacoli posti di fronte (entro una certa soglia) ai due sonar.

Il robot deve fermarsi solo quando ha finito di pulire tutto.

L'attività di pulizia deve terminare anche se:
\begin{itemize}
\item l'utente autorizzato invia il comando \texttt{STOP} dalla console;
\item la temperatura dell'ambiente supera la soglia prefissata;
\item l'ora corrente esce dall'intervallo prefissato;
\item il robot non riesce, in alcun modo, ad evitare un certo ostacolo (questo ostacolo insuperabile è un bastone orizzontale o verticale della lunghezza della stanza);
\item il robot ha terminato l'attività di pulizia, ovvero raggiunge la posizione finale.
\end{itemize}

Risultano essere presenti tre nodi di elaborazione: il robot, la console e dispositivi hardware come sensori e la lampada Hue.

\section{Analisi del problema}
Analizzando i progetti realizzati e presentati a lezione, si ha già a disposizione la console, realizzata come un frontend server in tecnologia Node.js. Essa presenta l'autenticazione degli utenti attraverso una coppia username-password come credenziali di accesso ed i comandi per pilotare il robot nelle sue azioni di base. Possono essere aggiunti facilmente i pulsanti per inviare i comandi di \texttt{START} e \texttt{STOP}.

Il sistema che si deve realizzare è distribuito, pertanto è necessario individuare un sistema di comunicazione tra le parti, ossia il frontend, il robot, i sensori e i sonar. Ciò può essere individuato nello scambio di messaggi supportato dall'infrastruttura MQTT, già integrata all'interno della console che si ha a disposizione. 

Nella scelta di lavorare all'interno di un ambiente virtuale, si ha a disposizione il progetto ConfigurableThreejsApp, che offre l'ambiente virtuale, dotato dei sonar, ed il robot virtuale. Esso è accessibile attraverso un'interfaccia web e controllabile attraverso una socket TCP.

Per realizzare un primo prototipo del robot con la logica applicativa che controlla l'attività di pulizia ci si appoggia a un linguaggio che permette di scrivere modelli eseguibili per garantire una rapida prototipazione. Questo linguaggio viene individuato in QActor, che permette anche di integrarsi nativamente con un'infrastruttura a scambio di messaggi via MQTT e lavorando su una base Java permette facilmente di avere accesso a delle API per gestire le socket.

Dato che il robot non comunica nativamente via messaggi occorre realizzare un adapter che intercetti i comandi di base inviati dalla console, o dalla logica applicativa durante la pulizia, per pilotare il robot e li traduca in un flusso di dati TCP che il robot possa comprendere. Questo adapter si occuperà anche di ricevere le segnalazioni dei sonar e tradurle in messaggi affinché gli altri componenti del sistema possano esserne a conoscenza.

Per gestire la logica applicativa si rende necessario un componente dedicato che riceva i comandi di \texttt{START} e \texttt{STOP} per controllare l'avvio e la terminazione dell'attività di pulizia, la gestisca e controlli che le condizioni specificate per operare siano soddisfatte.

Per ricevere informazioni su temperatura ambientale e ora corrente occorre realizzare due sensori, un termometro e un orologio, che possano inviare le rispettive informazioni. Poiché queste interessano solamente l'attività di pulizia automatica, possono essere intercettate solamente dal componente che si occupa della logica applicativa e usarle per aggiornare lo stato interno e terminare, se è il caso, l'attività di pulizia.

\subsection{Lampada Hue}
Per gestire la lampada che lampeggia occorre identificare un'entità che alterni ciclicamente tra due stati accendendo e spegnendo la lampada, cosa perfettamente adatta a un attore QActor. Per non interferire con le normali operazioni della logica applicativa risulta conveniente modellare questo \textit{blinker} come un attore separato controllato dalla logica applicativa e che a sua volta controlla la lampada direttamente.

\subsection{Pulizia e ostacoli}
Per guidare il robot nella pulizia della maggiore area possibile della stanza sarebbe possibile stabilire a priori un percorso che il robot segue in maniera indiscriminata, ma questo funziona solo se la morfologia della stanza è completamente nota, cosa non verificata in quanto, sebbene si conosca la forma della stanza, non si sa se e dove sono degli ostacoli.

Per gestire questo problema può venire in aiuto l'intelligenza artificiale dividendo la stanza in tile e sfruttando un algoritmo di ricerca per raggiungere tutti quelli da pulire e quando sono finiti, l'\texttt{end-point} davanti al \texttt{sonar2}.

L'algoritmo di ricerca porterà nativamente a evitare gli ostacoli e a rilevare se questi sono insuperabili impedendo di raggiungere l'\texttt{end-point} portando a uno stop anticipato alle operazioni di pulizia.

La rilevazione degli ostacoli richiede un lavoro ulteriore, rilevando quando il robot non riesce a portare a termine una delle mosse pianificate per pulire, cioè quando il sonar che ha a bordo segnala qualcosa. Quando il robot si sta muovendo in avanti e rileva che ha un ostacolo di fronte vuol dire che non può raggiungere il tile davanti a lui, questo tile sarà quindi marcato come ostacolo, il robot dovrà tornare indietro per riallinearsi con i tile ``virtuali" quindi annullare tutte le mosse pianificate e fare un nuovo piano. 

La rilevazione degli ostacoli porta automaticamente anche a realizzare una mappa della stanza man mano che il robot prova a pulire. L'algoritmo di ricerca che guida il robot dovrà anche aver cura di ignorare quelle parti della stanza che sono isolate da ostacoli e non pulirle perché irraggiungibili e andare comunque all'\texttt{end-point}.

\subsubsection{Ostacoli mobili}
Per gestire gli ostacoli mobili occorre ricontrollare tutti quei tile per cui è stato rilevato un ostacolo. A questo proposito l'algoritmo di ricerca viene in aiuto aggiungendo ai già usati stati dei tile (\texttt{0} per una cella non esplorata e non pulita, \texttt{1} per una cella libera e pulita e \texttt{x} per una cella con ostacolo) altri due stati: \texttt{t} per ostacolo rilevato e \texttt{p} per possibile ostacolo.

Durante la pulizia quando il robot rileva un ostacolo, secondo il processo già descritto, non marcherà più il tile come \texttt{x} ma come \texttt{t} e procederà a pulire le celle \texttt{0} evitando di passare su tile \texttt{t}. Quando non ci sono altri tile \texttt{0} (o quelli presenti non sono raggiungibili), tutti i tile \texttt{t} diventano marcati come \texttt{p} e il robot ora continuerà a pulire cercando di raggiungere i tile \texttt{0} e \texttt{p}, su cui ora può muoversi. Se riesce ad andare su questi tile saranno come prima marcati come \texttt{1}, se invece non riesce ad andare su un tile \texttt{p} questo sarà finalmente marcato come \texttt{x} (se non riesce ad andare su uno \texttt{0} sarà marcato come \texttt{t} ripetendo il processo).

\subsection{Mappatura}
Quando il robot completa la pulizia naturalmente fermandosi all'\texttt{end-point} salverà in un file la mappa generata, quindi dove sono gli ostacoli e marcando le altre celle come \texttt{0}. Nel caso il robot sia fermato durante la pulizia (manualmente o a causa dei sensori) oppure non termini all'\texttt{end-point} a causa di ostacoli insuperabili la mappa non sarà salvata perché non è stato possibile completarla o si è verificata una situazione imprevista.

Quando il robot viene avviato o si riconfigura per ripartire a pulire potrà caricare la mappa generata e quindi sapere già dove si trovano gli ostacoli, permettendo di semplificare il lavoro in quando non deve mapparli.

\subsection{Testing}
La parte più complessa del progetto è il QActor \texttt{cleaner} che si occupa di gestire i movimenti del robot sulla base di una mappa generata durante la pulizia e consultata utilizzato l'algoritmo A* (\prtref{prt:astar_prolog}).

Per semplificare il testing si è quindi isolato questo attore in un progetto dedicato (si veda il progetto \texttt{it.unibo.finaltask.testing}). Inoltre l'attore è stato leggermente modificato affinché le mosse non siano eseguite automaticamente in successione (come accade nel progetto principale) ma richiedono l'invio di un messaggio di controllo che ne scateni l'esecuzione, questo garantisce un controllo più granulare alla suite di testing che può svolgere il suo lavoro in maniera semplificata, in maniera analoga il reset allo stato in attesa di partire è manuale e scatenato dall'invio dello stesso messaggio. Questo è realizzato aggiungendo due stati (\texttt{waitMove} e \texttt{waitCleanKB}) per cui si può tornare al funzionamento nominale rendendo la transizione corrispondente al messaggio non più dipendente da questo, ma una $\varepsilon$-mossa.

La suite di testing procede quindi a caricare solamente l'attore (che non si muoverà in un ambiente né reale né virtuale) e quindi invierà opportuni messaggi di inizio e fine della pulizia automatica oltre che ai messaggi di controllo per permettere l'esecuzione delle mosse e la simulazione degli eventi del sonar montato sul robot. L'invio di tutti i messaggi sarà intercalato da un controllo dello stato del robot se sta pulendo o meno (usando un fatto ad hoc nella base di conoscenza) e da un check progressivo della mappa che conosce il robot dopo ogni singolo step (si veda la classe \texttt{it.unibo.cleaner.TestCleaner} all'interno della cartella \texttt{test}).

\section{Progetto}
Per mantenere lo stato del sistema ci si può appoggiare al supporto nativo del Prolog da parte di QActor per modellare una base di conoscenza che tenga traccia di temperatura e ora corrente, se si sta facendo la pulizia e qualunque altra informazione utile come la soglia di temperatura e l'intervallo di tempo in cui si può lavorare.

Non avendo a disposizione una realizzazione, fisica o virtuale, in grado di interagire in qualche modo con il sistema per come lo si è individuato finora, si è scelto di realizzarli da zero come sensori virtuali direttamente integrati con l'infrastruttura MQTT. È stato realizzato anche un mock per la lampada Hue per poter testare il funzionamento del robot quando quella fisica non è accessibile. Questo mock interagisce direttamente con i messaggi di controllo scambiati via MQTT, ma per controllare quella fisica occorre realizzare un adapter che intercetti i comandi e li traduca in opportune chiamate RESTful.

L'interazione tra le parti del sistema è gestita attraverso messaggi scambiati attraverso l'infrastruttura MQTT. Questi messaggi sono scambiati con una struttura particolare affinché possa interagire con l'infrastruttura QActor potendo quindi avere un comportamento dispatch, indirizzato ad un attore particolare, o evento, cioè diretto a tutti. Non volendo vincolarsi troppo ai nomi degli attori che compongono il sistema e per supportare anche contemporaneamente più attuatori, in particolare la lampada Hue fisica e il suo mock, risulta comodo scegliere di lavorare con eventi, limitando l'uso di dispatch solamente tra attori, in cui il linguaggio QActor garantisce il controllo di errori a livello semantico per i nomi dei destinatari. I dispatch verranno impiegati in particolare dell'adapter del robot virtuale che quando riceve i comandi di \texttt{START} e \texttt{STOP} ne delega la gestione all'attore che si occupa della logica applicativa.

L'uso dei dispatch risulta anche preferibile in quanto l'integrazione di QActor con MQTT non è completa e in alcuni casi l'uso di eventi via MQTT è causa di alcuni bug. Gli eventi (via MQTT) saranno quindi usati per interagire con sensori, attuatori e console, privilegiando invece dei dispatch (scambiati quindi direttamente dall'architettura QActor) per comunicazione diretta tra gli attori.

In quest'ottica, l'invio di nuovi dati da parte dei sensori avviene attraverso l'emissione di un evento \texttt{sensorEvent(ORIGIN, PAYLOAD)} che specifica il sensore coinvolto e le informazioni relative. In maniera analoga si ha l'evento \texttt{ctrlEvent(TARGET, PAYLOAD)} che specifica un attuatore e le informazioni per l'azione da compiere, questo sarà emesso solamente dalla logica applicativa e indirizzato alla lampada Hue per i comandi di spegnimento e accensione. L'evento di controllo sarà quindi essere intercettato direttamente dal mock per controllare la lampada virtuale e dal già citato adapter che si occuperà di tradurre l'evento in chiamate RESTful.

\subsection{Lampada Hue}
Per quanto riguarda lo stato della lampada, la logica applicativa non è interessata a sapere se questa è accesa o spenta, ma se questa sta lampeggiando o no. Lo stato mantenuto sarà quindi quello del blinker. Sarà l'attore blinker a inviare \texttt{ctrlEvent} per la lampada, mentre la logica applicativa invierà un \texttt{ctrlMsg} (con la stessa semantica di \texttt{ctrlEvent} ma scambiato come dispatch) al blinker.

\section{Implementazione di A*}\label{prt:astar_prolog}
L'algoritmo A* utilizzato è stato implementato ad hoc in Prolog (si veda il file \texttt{astar.pl} nel progetto principale o di testing contenente anche altri predicati di contorno per inizializzare la base di conoscenza). In questa sezione non si pretende di spiegare il funzionamento e la teoria alla base dell'algoritmo, ma di illustrare come questo sia stato implementato.

Il punto di accesso all'algoritmo è il predicato \texttt{findMove}/1 che per prima cosa decide verso quale cella muoversi utilizzando \texttt{establishGoal}/1. Questo predicato indicherà il tile in basso a destra se la stanza è stata interamente pulita altrimenti (nell'ordine) una cella marcata come \texttt{0} o una \texttt{p}.
La stanza è considerata pulita se la mappa contiene solamente celle \texttt{1} e \texttt{x} oppure se è presente il fatto \texttt{overrideCleanStatus}, aggiunto da \texttt{cleaner} quando rileva che le celle \texttt{0} rimanenti sono inaccessibili a causa di ostacoli.

Una volta stabilito il goal, \texttt{findMove}/1 ricava la posizione corrente nota dal robot e invoca l'algoritmo A* vero e proprio fornendo come lista dei nodi aperti lo stato (cioè cella e orientamento del robot) corrente, questa è anche la lista dei nodi chiusi. Un nodo aperto non è solo lo stato, ma è rappresentato da una lista di coppie mossa-stato risultante (la mossa per lo stato di partenza è nulla) garantendo così la ricostruzione del percorso pianificato. La lista dei nodi aperti viene mantenuta ordinata in ordine crescente secondo la funzione di costo calcolata assegnando costo unitario a ogni azione e utilizzando la distanza di Manhattan come euristica.

L'algoritmo vero e proprio è rappresentato dal predicato \texttt{findMove}/4 e funziona secondo un ciclo iterativo: se il primo nodo aperto (e quindi il più promettente) corrisponde al goal allora si è trovato il percorso ottimo, altrimenti:
\begin{enumerate}
	\item Si considera lo stato del primo nodo aperto e si invoca su questo la funzione successore ottenendo in \texttt{Succ} una lista di possibili stati futuri scelti tra movimento in avanti di una cella oppure rotazione a destra o sinistra di \ang{90}. Il movimento in avanti è restituito solamente se la cella di fronte al robot esiste e non è marcata come ostacolo \texttt{x} o \texttt{t}.
	\item Gli stati restituiti sono filtrati usando \texttt{filterVisited}/4 ottenendo in \texttt{SuccFilter} solo quegli stati che non sono già stati visitati e in \texttt{NewVis} la nuova lista di nodi chiusi. Il filtraggio discrimina a seconda di quale mossa lo genera:
	\begin{itemize}
		\item nel caso di una rotazione il confronto con la lista dei nodi chiusi considera sia la cella che l'orientamento;
		\item nel caso di un movimento in avanti il confronto considera solamente la cella, ignorando l'orientamento del robot.
	\end{itemize}
	\item Gli stati futuri filtrati sono ora ordinati con \texttt{sort}/3 secondo l'euristica crescente (il costo di cammino sarà uguale perché vengono tutti dallo stesso stato) ottenendo il risultato in \texttt{SuccFilterSort}.
	\item Gli stati futuri sono ora combinati con il cammino che li ha generati (mantenendo anche l'ordinamento) utilizzando il predicato \texttt{multiAppend}/3 che  restituisce i nuovi nodi in \texttt{Paths}.
	\item I nodi aperti non considerati e i nuovi nodi aperti appena generati sono unificati in un'unica lista utilizzando il predicato \texttt{mergeSorted}/4 che restituisce in \texttt{Lnext} tutti i nodi aperti ordinati secondo la funzione di costo crescente.
	\item L'algoritmo re-invoca se stesso passando la nuova lista di nodi aperti e chiusi ma lo stesso goal.
\end{enumerate}

Il piano generato da A* viene quindi utilizzato da \texttt{registerMoves}/1 che salva nella base di conoscenza le mosse nell'ordine con cui devono essere eseguite.

\subsection{Predicati ausiliari}
L'algoritmo e \texttt{cleaner} che lo usa sfruttano anche dei predicati ausiliari per gestire la base di conoscenza. Di seguito sono introdotti brevemente, maggiori dettagli possono essere trovati direttamente nei commenti a corredo di ogni predicato all'interno del codice:
\begin{itemize}
	\item \texttt{h}/3: calcola l'euristica per una certa cella relativamente a un certo goal.
	\item \texttt{rotate}/2: supporto alla funzione successore \texttt{next}/2, si occupa di generare solamente le rotazioni.
	\item \texttt{jobDone}: determina se il robot deve fermarsi autonomamente sulla base di \texttt{R-End}.
	\item \texttt{loadStatus}: utilizzando \texttt{loadStatus}/1 e \texttt{loadCol}/2 popola la base di conoscenza con una mappa vuota (tutte le celle a \texttt{0}).
	\item \texttt{loadInitialPosition}: registra la posizione corrente iniziale del robot all'interno della base di conoscenza.
	\item \texttt{printStatus}: utilizzando \texttt{printRow}/1 e \texttt{listify}/3 stampa su standard output la mappa corrente salvata nella base di conoscenza.
	\item \texttt{visit}/1: segna la cella specificata come \texttt{1} (solo se \texttt{0} o \texttt{p}). \texttt{visitCurrent} invoca questo predicato passando la posizione corrente.
	\item \texttt{obstacle}/1: segna la cella specificata come ostacolo. Una cella \texttt{0} diventa \texttt{t} e una cella \texttt{p} diventa \texttt{x}.
	\item \texttt{recheck}/1: segna la cella specificata come \texttt{p} solamente se era marcata come \texttt{t}. Questo predicato viene invocato dal robot su tutte le celle quando non ha più celle \texttt{0} da pulire innescando il ricontrollo degli ostacoli rilevati per pulire dove fossero presenti degli ostacoli mobili.
	\item \texttt{isWalkable}/1: se è possibile transitare sulla cella specificata. Questo è vero solo per le celle \texttt{1}, \texttt{0} e \texttt{p}, quest'ultimo caso permette di ricontrollare le celle segnate come possibili ostacoli in combinazione con \texttt{establishGoal}/1.
	\item \texttt{registerNext}/1: registra la cella specificata come stato futuro durante l'esecuzione di una mossa.
	\item \texttt{actualizeNext}: distrugge un eventuale stato futuro che diventa lo stato corrente, la cella corrispondente viene marcata come \texttt{1}.
	\item \texttt{nextIsObstacle}: distrugge un eventuale stato futuro e la cella corrispondente viene segnata come ostacolo con \texttt{obstacle}/1. Il robot viene lasciato nella posizione corrente.
\end{itemize}

\section{Log}

Per i progetti parziali relativi ai singoli sprint si faccia riferimento ai corrispondenti tag/release.

\subsection{1° sprint -- 23-27/06/2018}
Ci siamo concentrati sull'analisi dei requisiti e del problema a livello generale per individuare le parti che abbiamo già a disposizione da progetti svolti a lezione. Queste parti sono state assemblate assieme a un mock per i dispositivi hardware (sensori e attuatori) richiesti per avere un primo prototipo funzionante, ma senza logica applicativa, del sistema.

\begin{itemize}
	\ttfamily
	\item R-Start
\end{itemize}

\subsection{2° sprint -- 27/06-04/07/2018}
Supporto dello stato delle risorse come valore di temperatura e ora corrente, pulizia come movimento avanti e indietro per un tempo indeterminato per controllare lo stop manuale o per mancata verifica delle condizioni di temperatura/ora.

\begin{itemize}
	\ttfamily
	\item R-TempOk
	\item R-TimeOk
	\item R-BlinkHue
	\item R-Stop
	\item R-TempKo
	\item R-TimeKo
\end{itemize}

\subsection{3° sprint -- 04-11/07/2018}
Pulizia di tutta la stanza e gestione degli ostacoli fissi: rilevati, mappati ed aggirati.

\begin{itemize}
	\ttfamily
	\item R-FloorClean
	\item R-AvoidFix
	\item R-Obstacle
	\item R-End
	\item R-Map
\end{itemize}

\subsection{4° sprint -- 11-19/07/2018}
Gestione degli ostacoli mobili e uso della mappa generata.

\begin{itemize}
	\ttfamily
	\item R-AvoidMobile
\end{itemize}

\subsection{5° sprint -- 20/07/2018}
Testing automatico del QActor \texttt{cleaner}.

\end{document}
